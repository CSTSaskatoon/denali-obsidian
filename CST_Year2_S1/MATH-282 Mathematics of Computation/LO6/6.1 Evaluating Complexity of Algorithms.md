How can we measure the amount of work done by computers? How can we compare algoithms or programs to see which is more efficient? (**Efficiency can be speed/time/number of steps, or storage space/memory/other resources**)

We could measure the time used to run a program, but that depends on the data and machine used.
- Looks at a particular implementation, rather than the solution in general terms
- Depends on the machine (so often **benchmarks** are used to compare machines)
- Depends on the test cases (data used)

Another solution: analyze the properties of the alogrithm
- Focus on time/speed/number of steps (could also look at storage space)
- Focus mostly on worst-case analysis
- Interested in "large" amounts of data - efficiency is related to some key indicator (usually *n*)
- Also need to take into account that not all steps are the same
	- Beware of method calls (or similar algorithmic steps), because they may involve a lot of steps - must calculate and account for those steps too
	- For instance, to add an item to a sorted list (and maintain the sort order), we could do the following

```cs
list.Add(item);
list.Sort();
```
This appears to be 2 steps, but sorting is hard so it goes from $n * \log n$ to $n^2$ steps, depending on how it's done, so the order of the process is the same as the sorting process

### Binary Search
Factor to be analyzed: Time (Number of steps, speed)
Situation to be analyzed: Worst Case
Explanation of Algorithm: Item is not in the list, or all other items have been eliminated
Key Step: Comparisons
Parameter for analysis: n, the number of items in the list

#### Process
Only looking at comparisons
$(2C + 1C + 1C) * \text { loops } + 1C = 4C * \text { loops } + 1C$ steps
$4C * \log _2 n + 1C \text { steps } = 4 * \log n + 1$ comparisons since the loop repeats for $\log _2 n$ times
ignoring constants: *O(log n)*

#### Table
Binary search assumes:
- You have an indexable list/array
- Your list/array is sorted

| Index # | Value |                                                |
| ------- | ----- | ---------------------------------------------- |
| 0       | 5     | lowerlimit1 = 0                                |
| 1       | 5     |                                                |
| 2       | 8     |                                                |
| 3       | 13    |                                                |
| 4       | 16    |                                                |
| 5       | 19    |                                                |
| 6       | 22    |                                                |
| 7       | 30    | test1 = 7                                      |
| 8       | 61    | lowerlimit2 = 8                                |
| 9       | 65    |                                                |
| 10      | 72    |                                                |
| 11      | 82    | test2 = 11                                     |
| 12      | 83    | lowerlimit3 = 12                               |
| 13      | 87    | test3 = 13                                     |
| 14      | 89    | lowerlimit4Â  = 14, test4 = 14                  |
| 15      | 96    | lowerlimit5 = 15, upperlimit1 = 15, test5 = 15 |
|         |       | lowerlimit6 = 16                               |
### Logarithms
A number to which a base must be raised to get a value *n*
Corresponds to the number of digits in the values in that base
defaults to base 10

## Analysis of Matrix Operations
### Matrix Addition
Factor to be analyzed: *Time*
Situation to be analyzed: *Square Matrices (assumed) of size n by n*
Explanation of situation: *Number of rows is the same as the number of columns*
Key Step: *Accessing the matrix*
Parameter for Analysis: *n is the number of rows or columns of the square matrix*

#### Analysis
We can ignore the 3 assignments and 2 comparisons at the start since they aren't matrix accesses and also aren't in the loops
There are two loops, each loop is carried out n times (once through every row, once through every column)
Since the loops are nested, it is $\color{lightgreen}n * n$ steps (or $\color{lightgreen}n^2$) to add the matrices
technically $\color{lightgreen}3n^2$ because we get the two values and set the value in the sum matrix
we can ignore the constants however, so it's still $\color{red}O(n^2)$

#### Shortcut Analysis
There are two loops that are nested, each loop is carried out $\color{yellow}n$ times. There are therefore $\color{lightgreen}n^2$ steps being done
Technically the creation of the new matrix is also a complex step, but since it just allocates a chunk of memory we will ignore it.

### Matrix Multiplication
Factor to be analyzed: *Time*
Situation to be analyzed: *Square Matrices (assumed) of size n by n*
Explanation of situation: *Number of rows is the same as the number of columns*
Key Step: *Accessing the matrix*
Parameter for Analysis: *n is the number of rows or columns of the square matrix*

#### Analysis
To multiply the matrix, there are 3 loops
- First (outermost) loop is done $\color{yellow}n$ times (once every row for the product)
- Second (middle) loop is done $\color{yellow}n$ times (once for every column in the product)
- Third (innermost) loop is done $\color{yellow}n$ times (once for every column in the left op or row in the right op)
- The loops are nested, so we multiply steps which leaves us with $\color{lightgreen}n * n * n$ or $\color{lightgreen}n^3$

The result is $\color{red} O(n^3)$

### Gauss Jordan Elimination
Factor to be analyzed: *Time*
Situation to be analyzed: *Worst Case*
Explanation of situation: *Every pivot row must be swapped with last row*
Key Step: *Accessing the matrix*
Parameter for Analysis: *n is the number of unknowns/equations (so the augmented matrix is size n by n + 1)*

#### Analysis
Copying the matrix involves two nested loops which each take $n$ steps, so $\color{lightgreen} n^2$ steps in total
The loop to go through every pivot row in the matrix is carried out $\color{yellow} n$ times. For each pivot row we must
- Go through `systemSolvable()` - Total $\color{lightgreen} 4n^2 + 4n + n$ or $\color{red} O(n^2)$
	- One matrix access at the start, then it loops through every remaining row (so $n - 1$ loops the first time, then $n - 2$ loops, then $n - 3$ loops and so on until 0) - we can treat this as if the loop was done $\color{yellow} n$ times
	- One matrix access inside the loop - it's done $\color{lightgreen} n^2$ times for all rows in total
	- Then we do a loop $\color{yellow} n + 1$ times, but it's effectively **NOT** nested inside the previous loop, it's done for every pivot row, so $\color{lightgreen} 4(n + 1) * n$ matrix accesses to switch for all rows in total
- We get the pivot element ($\color{yellow} 1$ matrix access)
	- Go through the pivot row and access every element twice for every column, so there are $\color{yellow} 2 * (n + 1)$ matrix accesses for all $n$ of the pivot rows, so $\color{lightgreen} n * 2 * (n + 1)$ matrix accesses to divide each pivot row element for all rows in total, so $\color{lightgreen} 2n^2 + 2n$ matrix accesses in total or $\color{red} O(n^2)$
- Then for the remaining rows, or $\color{yellow} n - 1$ loops, we get the factor ($\color{yellow} 1$ matrix access), so that's carried out $\color{lightgreen} n * (n - 1)$ times
	- Then there are 3 matrix accesses for every column in every remaining row for every pivot row, so that's $3 * n * (n - 1) *\color{yellow} (n - 1)$ matrix accesses
	- So getting $0$'s in every column other than the pivot row involves $\color{lightgreen} n * (n - 1) + \color{lightgreen} 3 * n * (n - 1) * (n + 1)$ steps, which is roughly $\color{lightgreen} n^2 + 3n^3$ which is $\color{red}O(n^3)$

So the entire process takes $\color{cyan} O(n^2) + O(n^2) + O(n^2) + O(n^3)$ steps, so the entire process is $\color{red}O(n^3)$

#### Shortcut Analysis
There are two nested loops ($\color{red}O(n^2)$) for system solvable, 2 nest loops for the pivot row ($\color{red}O(n^2)$), and 3 nested loops with each loop being done roughly $\color{yellow}n$ times for getting all the $0$'s ($\color{red}O(n^3)$)

## Summary of Rules
Recall we said that to add an item to a sorted list and maintain the sort order, we could Add the item to the start or end and then sort it, but this would take as much work as sorting the list. An alternative would be to do a *binary search* on the list ($\color{red} O(\log _2 n)$ steps) and then add the item into the correct spot (could take $\color{yellow}n$ steps if we're working with an array, but we ignore smaller terms so it would be a $\color{red} O(n)$ process

Another alternative would be to do a *sequential search* on the ordered list and add the item in the correct spot we encountered.
- this would be $\color{red} O(n)$ for the search and $\color{red} O(1)$ for putting the item in the right spot, so overall it would be $\color{red} O(n + 1)$ but we ignore constants so $\color{red} O(n)$

Ignore values of lower order in the number of steps (they are unimportant for large values of $n$) **if added**
- For instance, if there are $\color{lightgreen}3n^2 + 7n$, ignore the $\color{yellow}7n$ and focus on $\color{lightgreen}3n^2$
- **CANNOT** ignore lower orders if they are multiplied (Ex. $\color{lightgreen}n * \log n$ we can't ignore $\color{yellow} \log n$ so it would be $\color{red} O(n * \log n)$)

Ignore constants (they become unimportant compared to other order of complexity)
- for instance, if there are $\color{lightgreen}4n^2 + 3$ steps, ignore the $\color{yellow}4$ and the $\color{yellow}3$ and focus on the $\color{lightgreen}n^2$ so the algorithm would be $\color{red} O(n^2)$

Look at *loop/recursion* - they cause the work to be done repetitively
- If a loop cuts the data in half every time, it is doing $\color{lightgreen} \log _2 n$ steps
- If the loops are nested, multiply the number of steps that each loops does (for instance, $\color{lightgreen}n * n = n^2$ total loops)
- If the loops are **NOT** nested (one part of the algorithm is done completely before the next part starts), simply add the steps done by each loop (for instance, $\color{lightgreen}n + n = 2n$, so this algorithm would be $\color{red} O(n)$)

When done you can compare the order of similar algorithms

